"""Code that evaluates the quality of the MVM products generated by the drizzlepac package.

Visualization of these Pandas DataFrames with Bokeh can follow the example
from:

https://programminghistorian.org/en/lessons/visualizing-with-bokeh

PUBLIC INTERFACE FOR THIS MODULE
 - build_mvm_plots(HDF5_FILE, output_basename='', display_plot=False):

pthon mvm_quality_graphics.py mvm_qa_dataframe.h5

"""

# Standard library imports
import argparse
import collections
from datetime import datetime
import logging
import math
import os
import pdb
import re
import sys
import time

# Related third party imports
import pandas as pd

from bokeh.layouts import row, column, gridplot
from bokeh.plotting import figure, output_file, save, show
from bokeh.models import ColumnDataSource
from bokeh.models.tools import HoverTool
from bokeh.palettes import viridis, Category20, Category20c, Spectral5
from bokeh.transform import factor_cmap

# Local application imports
from drizzlepac import util, wcs_functions
from drizzlepac.haputils.pandas_utils import PandasDFReader, get_pandas_data
from stsci.tools import logutil


__taskname__ = 'mvm_quality_graphics'

MSG_DATEFMT = '%Y%j%H%M%S'
SPLUNK_MSG_FORMAT = '%(asctime)s %(levelname)s src=%(name)s- %(message)s'
log = logutil.create_logger(__name__, level=logutil.logging.NOTSET, stream=sys.stdout,
                            format=SPLUNK_MSG_FORMAT, datefmt=MSG_DATEFMT)
# ----------------------------------------------------------------------------------------------------------------------
# Module level variables
color26 = ['#1f77b4', '#393b79', '#aec7e8', '#ff7f0e', '#ffbb78', '#5254a3', '#2ca02c',
           '#98df8a', '#6b6ecf', '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#7b4173',
           '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#a55194', '#7f7f7f', '#c7c7c7',
           '#bcbd22', '#dbdb8d', '#ce6dbd', '#17becf', '#9edae5']

wcs_list = ['FIT_SVM_GAIAEDR3', 'FIT_EVM_GAIAEDR3', 'FIT_REL_GAIAEDR3', 'FIT_IMG_GAIAEDR3',
            'FIT_SVM_GAIADR2', 'FIT_EVM_GAIADR2', 'FIT_REL_GAIADR2', 'FIT_IMG_GAIADR2',
            'FIT_SVM_GAIADR1', 'FIT_EVM_GAIADR1', 'FIT_REL_GAIADR1', 'FIT_IMG_GAIADR1',
            'FIT_SVM_GSC242', 'FIT_EVM_GSC242', 'FIT_REL_GSC242', 'FIT_IMG_GSC242',
            'FIT_SVM_2MASS', 'FIT_EVM_2MASS', 'FIT_REL_2MASS', 'FIT_IMG_2MASS',
            'FIT_SVM_NONE', 'FIT_EVM_NONE', 'FIT_REL_NONE', 'FIT_IMG_NONE',
            'HSC30', 'GSC240']

def build_mvm_plots(data_source, output_basename='', display_plot=False, log_level=logutil.logging.INFO):
    """Create all the plots for the results generated by these comparisons

    Parameters
    ----------
    data_source : str
        Filename for master data file which contains all the results.  This will
        typically be an HDF5 file generated by the JSON harvester.

    output_base_filename : str
        Base name for the HMTL file generated by Bokeh.

    display_plot : bool, optional
        Option to display the plot to the screen
        Default: False

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    -------
    Nothing.
    """
    log.setLevel(log_level)
    if output_basename == '':
        output_basename = "mvm_qa"
    else:
        output_basename = "{}_mvm_qa".format(output_basename)

    # Generate the WCS graphics
    try:
        wcs_graphics_driver(data_source, output_basename, display_plot, log_level=log_level)
    except Exception:
        log.warning("WCS comparison plot generation encountered a problem.")
        log.exception("message")
        log.warning("Continuing to next plot...")

# -----------------------------------------------------------------------------
# Functions for generating each data plot
# -----------------------------------------------------------------------------
# WCS graphic
#
def wcs_graphics_driver(storage_filename, output_base_filename='', display_plot=False,
                        log_level=logutil.logging.INFO):
    """Driver to load the data from the storage file and generate the graphics.

    Parameters
    ==========
    storage_filename : str
        Name of the storage file for the Pandas dataframe created by the harvester.

    output_base_filename : str, optional
        Base name for the HMTL file generated by Bokeh.

    display_plot : bool, optional
        Option to display the plot in addition to writing out the file.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    =======
    Nothing
    """
    log.setLevel(log_level)

    # Retrieve the relevant dataframe columns as specified by the column_restring, as
    # well as some additional columns for context where the latter is done by default
    log.info('Retrieve Pandas dataframe from file {}.\n'.format(storage_filename))
    wcs_dataDF = get_wcs_data(storage_filename, column_restring='p\d\d\d\dx\d\dy\d\d')

    # Dictionary which defines how old column names map to new column names
    wcs_columns = {}

    # Rename the columns to abbreviated text as the graph titles further
    # document the information.
    if bool(wcs_columns):
        for old_col_name, new_col_name in wcs_columns.items():
            wcs_dataDF.rename(columns={old_col_name: new_col_name}, inplace=True)

    # Generate the WCS graphic for specific skycell layer
    generate_wcs_graphic(wcs_dataDF, output_base_filename, display_plot, log_level)


def generate_wcs_graphic(wcs_dataDF, output_base_filename='', display_plot=False,
                         log_level=logutil.logging.NOTSET):
    """Generate the graphics associated with this particular type of data.

    Parameters
    ==========
    wcs_dataDF : Pandas dataframe
        A subset of the input Dataframe consisting only of columns associated
        with the gathering of WCS data

    output_base_filename : str
        Base name for the HMTL file generated by Bokeh.

    display_plot : bool, optional
        Option to display the plot to the screen
        Default: False

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default: 20 or 'info'.

    Returns
    =======
    Nothing

    HTML file is generated and written to the current directory.
    """
    log.setLevel(log_level)

    # Set the output file immediately as advised by Bokeh.
    if output_base_filename == '':
        output_base_filename = 'mvm_qa_wcs'
    else:
        output_base_filename = '{}_mvm_qa_wcs'.format(output_base_filename)
    output_file(output_base_filename + '.html')

    # Suffix for the column data needed for the bar chart
    suffix = ['wcsname', 'wcs_value']

    # Gather information regarding constituents of each skycell (p####x##y##)
    # 0) Determine all the skycells in use
    # 1) Identify all layers of a skycell 
    # 2) Determine number of exposures in each layer
    # 3) For each layer make a set of the WCSNAMEs
    # 4) Compute the % of exposures using each WCSNAME
    # 5) Plot as a bar chart

    # Determine all the skycell names
    column_names = [item for item in wcs_dataDF.columns if re.search('p\d\d\d\dx\d\dy\d\d.filename', item)]
    skycell_names = [item.split('.')[0] for item in column_names]
    log.info('There are {} skycell datasets.'.format(len(skycell_names)))

    # Get all the row names (dataframe index) - these are the layers of the skycell
    all_rows = wcs_dataDF.index.tolist()

    # Set up for a list of plots
    plots = []

    # Loop over the skycell names for the graphics to be generated
    for skycell in skycell_names:

        # Set up the names of the columns needed for the bar graphic
        bar_columns = [skycell + '.' + item for item in suffix]

        # Get all the layer names for just this skycell
        layer_names = [item for item in all_rows if re.search(skycell, item)]
        num_layers = len(layer_names)

        # This is a dataframe of just one skycell
        df = wcs_dataDF.loc[layer_names, bar_columns]
 
        # Determine the number of exposures and unique WCS names in the layer
        # row is a list of two lists, wcsnames and wcs_values
        wcsnames_all_layers = []
        layer_dict = {}
        max_num_expo = 0
        for layer in layer_names:
            wcs_dict = {}
            row = df.loc[layer].tolist()
            num_exposures = len(row[0])
            max_num_expo = num_exposures if num_exposures > max_num_expo else max_num_expo
            set_wcsnames = set(row[0])
            wcsnames_all_layers.extend(row[0])
            for item in set_wcsnames:
                # How many times is WCSNAME in the list of WCSNAMEs for this layer
                wcs_dict[item] = row[0].count(item)
            layer_dict[layer] = wcs_dict

        # Get the unique WCSNAMEs as a list
        wcsnames_all_layers = list(set(wcsnames_all_layers))

        # These machinations were done to push the WCS information into a dataframe
        # which can then be utilized by Bokeh for a vertical stacked bar graph

        # The new columns of the skycell dataframe are all the WCSNAMEs in use
        # Want to ensure the data is added to the correct row (aka layer), so add
        # a column of zeros first.
        for item in wcsnames_all_layers:
            empty_col = [0 * i for i in range(num_layers)]
            df[item] = empty_col 

        # Now fill in the proper data
        for layer in layer_names:
            for item in wcsnames_all_layers:
                try:
                    df.loc[layer,item] = layer_dict[layer][item]
                # This layer just did not have any exposures with this WCSNAME
                except KeyError:
                    pass

        # Create a new column using the index values -- seems to be easier to use
        df['LAYER_NAME'] = df.index.str[24:-4]
        grouped = df.groupby('LAYER_NAME')[wcsnames_all_layers].sum()

        # Setup the source of the data to be plotted so the axis variables can be
        # referenced by column name in the Pandas dataframe
        sourceCDS = ColumnDataSource(grouped)
        layers = sourceCDS.data['LAYER_NAME'].tolist()

        # Map the WCSNAMEs to specific colors so any particular WCSNAME will always have
        # the same color
        dict_wcs_color = dict(zip(wcs_list, color26))
        colors = [dict_wcs_color.get(item) for item in wcsnames_all_layers]

        # The graphic
        p = figure(x_range=layers)
        p.xaxis.major_label_orientation = math.pi/4
        p.title.text = 'Sky Cell ' + skycell.upper()
        p.xaxis.axis_label = 'Sky Cell Layer'
        p.yaxis.axis_label = 'Count of WCS Names'
        p.x_range.range_padding = 0.1
        p.y_range.end = max_num_expo + (0.3 * max_num_expo)
        if p.y_range.end % 2 > 0:
           p.y_range.end += 1

        legend = wcsnames_all_layers
        p.vbar_stack(stackers=wcsnames_all_layers,
             x='LAYER_NAME', source=sourceCDS,
             legend_label = wcsnames_all_layers,
             width=0.5, color=colors)
        p.legend.location = 'top_left'

        plots.append(p)

    # Setup the grid to have two columns and multiple rows as it is not know a priori 
    # how many datasets will be processed
    grid = gridplot(plots, ncols=2)

    # Display and save
    if display_plot:
        show(grid)
        log.info("Output HTML graphic file {} displayed in browser and has been written.\n".format(output_base_filename + ".html"))
    # Just save
    else:
        save(grid)
        log.info("Output HTML graphic file {} has been written.\n".format(output_base_filename + ".html"))


# -----------------------------------------------------------------------------
# General Utility functions for plotting
#


def get_wcs_data(storage_filename, wcs_columns = None, column_restring = '', log_level=logutil.logging.NOTSET):
    """Load the harvested data, stored in a storage file, into local arrays.

    Parameters
    ==========
    storage_filename : str
        Name of the storage file for the Pandas dataframe created by the harvester.

    wcs_columns : dict
        Dictionary of original column names (keys) as stored in the Pandas dataframe
        and the corresponding simple name (values) which is often more practical for use.

    column_restring : str
        Substring to use to match as a regular expression against all available
        column names. This parameter is ONLY used in the instance column_names
        is None.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default: 20 or 'info'.

    Returns
    =======
    wcs_dataDF : Pandas dataframe
        Dataframe which is a subset of the input Pandas dataframe which
        consists of only the requested columns and rows, as well as any columns provided
        by pandas_utils for free.

    Note: This routine is different from the nominal get_pandas_data() in that it tries to
    compensate in case on the of requested columns (apriori or aposteriori) is missing.
    """
    log.setLevel(log_level)

    # Instantiate a Pandas Dataframe Reader (lazy instantiation)
    df_handle = PandasDFReader(storage_filename, log_level=log_level)

    # Get the relevant column data
    wcs_dataDF = df_handle.get_columns_HDF5(column_restring=column_restring)

    # If no dataframe were returned, there was a KeyError because columns were
    # not present in the original dataframe versus the columns contained NaNs.
    if wcs_dataDF.empty:
        log.critical("Critical columns not found in storage Pandas dataframe: {}.\n".format(
            storage_filename))
        sys.exit(1)

    log.info("WCS data has been retrieved from the storage Pandas dataframe: {}.\n".format(storage_filename))

    return wcs_dataDF


if __name__ == "__main__":
    """Simple command-line interface. That is all.
    """
    # process command-line inputs with argparse
    parser = argparse.ArgumentParser(description='Generate MVM quality assessment plots based on information'
                                                 ' stored in the user-specified .h5 file.')
    parser.add_argument('input_filename',
                        help='Input .h5 file produced by diagnostic_json_harvester.py that holds the '
                             'information to plot.')
    parser.add_argument('-d', '--display_plot', required=False, action='store_true',
                        help='If specified, plots will be automatically opened in the default web browser as '
                             'they are generated. Otherwise, .html plot files will be generated but not '
                             'opened.')
    parser.add_argument('-l', '--log_level', required=False, default='info',
                        choices=["critical", "error", "warning", "info", "debug", "notset"],
                        help='The desired level of verboseness in the log statements displayed on the screen '
                             'and written to the .log file.')
    parser.add_argument('-o', '--output_basename', required=False, default='',
                        help='Base name for the HMTL file generated by Bokeh.')
    user_args = parser.parse_args()

    # verify that input file exists
    if not os.path.exists(user_args.input_filename):
        err_msg = "File {} doesn't exist.".format(user_args.input_filename)
        log.critical(err_msg)
        sys.exit(err_msg)
    # set up logging
    log_dict = {"critical": logutil.logging.CRITICAL,
                "error": logutil.logging.ERROR,
                "warning": logutil.logging.WARNING,
                "info": logutil.logging.INFO,
                "debug": logutil.logging.DEBUG,
                "notset": logutil.logging.NOTSET}
    log_level = log_dict[user_args.log_level]
    log.setLevel(log_level)

    # execute plot generation!
    build_mvm_plots(user_args.input_filename, output_basename=user_args.output_basename,
                    display_plot=user_args.display_plot, log_level=log_level)
