""" Definition of PandasDFReader class for reading the SVM harvester file.

    This class is responsible for reading the SVM "harvester file" which 
    contains a Pandas dataframe stored in an HDF5 file.  The harvester file
    is the collection of JSON output generated by the SVM quality analysis
    tests.

"""
import array
from bokeh.layouts import row
from bokeh.plotting import figure, output_file, show
from bokeh.models import ColumnDataSource, Label
import csv
import glob
import json
import logging
import os
import sys
import pandas as pd
import pathlib
import shutil
import traceback

from stsci.tools import logutil
from astropy.io import fits
import numpy as np

MSG_DATEFMT = '%Y%j%H%M%S'
SPLUNK_MSG_FORMAT = '%(asctime)s %(levelname)s src=%(name)s- %(message)s'
log = logutil.create_logger(__name__, level=logutil.logging.NOTSET, stream=sys.stdout,
                            format=SPLUNK_MSG_FORMAT, datefmt=MSG_DATEFMT)
__version__ = 0.1
__version_date__ = '08-Jun-2020'

DETECTOR_LEGEND = {'UVIS': 'magenta', 'IR': 'red', 'WFC': 'blue', 
                    'SBC': 'yellow', 'HRC': 'black'}

class PandasDFReader:
    """ A base class to read a Pandas dataframe generated by the HAP harvester.
    """
    def __init__(self, harvester_filename, log_level):
        # set logging level to user-specified level
        log.setLevel(log_level)
        self.log_level = log_level

        # Check for the existence of the input file.  There is no race condition
        # here, so this style of checking is fine.
        path = pathlib.Path(harvester_filename)
        if not path.is_file():
            log.error('Pandas dataframe file {} does not exist.'.format(harvester_filename))
            raise ValueError('Pandas dataframe file {} does not exist.')

        self.harvester_filename = harvester_filename

        # Lazy attribute creation
        self._dataframe = pd.DataFrame()

    def get_columns_CSV(self, column_names):
        """ Method to do the actual reading of dataframe and get the data in the
            specified columns.

            Parameters
            ----------
            column_names : list
            A list of the column names which specify the desired data.

            Returns
            -------
            column_data : Pandas dataframe
            A Pandas dataframe containing only the specified named columns where
            any rows containing NaNs have been eliminated.
        """
        # Only read the input dataframe once
        if self._dataframe.empty:
            self._dataframe = pd.read_csv(self.harvester_filename)

        # Get the requested columns and eliminate all rows which have
        # Generate a new column in the HAP dataframe, 'inst_det'.  Also append
        # this column to the user requested columns.  
        self._dataframe['inst_det'] = self._dataframe['gen_info.instrument'] + '/' + self._dataframe['gen_info.detector']

        # NaNs in any of the requested columns.
        #column_data = self._dataframe.loc[:, column_names].dropna()

        column_data = self.extract_columns(column_names)

        return column_data

    def get_columns_HDF5(self, column_names, do_drop=True):
        """ Method to do the actual reading of dataframe and get the data in the
            specified columns.

            Parameters
            ----------
            column_names : list
            A list of the column names which specify the desired data.

            do_drop : bool, optional (default is True indicating to drop the rows)
            Option to drop rows which contain NaNs in any of the requested columns.
            Option is set to True for backwards compatibility.

            Returns
            -------
            column_data : Pandas dataframe
            A Pandas dataframe containing only the specified named columns where
            any rows containing NaNs have been eliminated.
        """
        # Only read the input dataframe once
        if self._dataframe.empty:
            hdf5 = pd.HDFStore(self.harvester_filename, mode="r")

            # Get the zeroth key from the file as there is really only one dataframe
            # stored in the file - just do not assume its key.
            key0 = hdf5.keys()[0]
            self._dataframe = hdf5.get(key0)

            hdf5.close()

        # Generate a new column in the HAP dataframe so the instrument and detector 
        # can be reported in the same entry as a HoverTool tooltip
        self._dataframe['gen_info.inst_det'] = self._dataframe['gen_info.instrument'] + '/' + self._dataframe['gen_info.detector']
 
        # Generate a new column in the HAP dataframe which contains a color associated
        # with each instrument/detector combination.  These colors are then used for the
        # graphics so the data is consistently represented by the same set of colors.
        self._dataframe['gen_info.color'] = self._dataframe['gen_info.detector']
        for key, value in DETECTOR_LEGEND.items():
            self._dataframe.loc[self._dataframe['gen_info.detector'] == key, 'gen_info.color'] = value

        # TO DO - fix later
        # Always get all the "header" and "general information" columns
        header_cols = [hd_cols for hd_cols in self._dataframe if 'header' in hd_cols]
        #gen_info_cols = [hd_cols for hd_cols in self._dataframe if 'gen_info' in hd_cols]
        print('h: {}'.format(header_cols))
        #print('g: {}'.format(gen_info_cols))
        #print("col: {}".format(list(column_names)))

        # Return all the header, gen_info, 'inst_det', 'color', and user-requested columns!
        #final_columns_to_get = list(column_names) + header_cols + gen_info_cols
        #print("f: {} Type: {}".format(final_columns_to_get, type(list(final_columns_to_get))))

        column_data = self.extract_columns(column_names)
        # column_data = self.extract_columns(final_columns_to_get)


        return column_data


    def extract_columns(self, column_names, do_drop = True):

        # Get the requested columns and eliminate, upon request, rows which have
        # NaNs in *any* of the requested columns.
        column_data = pd.DataFrame()
        try:
            if do_drop:
                column_data = self._dataframe.loc[:, column_names].dropna()
            else:
                column_data = self._dataframe.loc[:, column_names]
        # Columns may not be present in the dataframe for legitimate reasons
        except KeyError:
            log.warning("Column data missing from the Pandas dataframe.  All expected WCS solutions"
                        " ('a priori' or 'a posteriori') may not be available.")
        # Some other possibly more serious problem
        except Exception:
            log.critical("Unable to extract column data from the Pandas dataframe, {}.\n".format(self.harvester_filename))
            sys.exit(1)

        return column_data
